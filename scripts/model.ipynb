{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "#import fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import get_cv_score, custom_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extended_path = r\"../data/data_extended_v1_1/data_v1_1.parquet.gzip\"\n",
    "df = pd.read_csv(data_extended_path)\n",
    "#df = pd.read_parquet(data_extended_path, engine='fastparquet')\n",
    "#pd.read_parquet(r\"../data/data_extended_v1_1/data_v1_1.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subid</th>\n",
       "      <th>firstrun.gopast</th>\n",
       "      <th>firstfix.dur</th>\n",
       "      <th>dur</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>lang</th>\n",
       "      <th>FF_norm</th>\n",
       "      <th>FP_norm</th>\n",
       "      <th>TF_norm</th>\n",
       "      <th>lang_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DU_04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>du</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050674</td>\n",
       "      <td>0.084579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DU_04</td>\n",
       "      <td>944.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>du</td>\n",
       "      <td>0.172074</td>\n",
       "      <td>0.029894</td>\n",
       "      <td>0.087495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DU_04</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>du</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DU_04</td>\n",
       "      <td>323.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>du</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DU_04</td>\n",
       "      <td>462.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>du</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>0.048305</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732238</th>\n",
       "      <td>tr_52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>26247.0</td>\n",
       "      <td>tr</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.060883</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732239</th>\n",
       "      <td>tr_52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>26247.0</td>\n",
       "      <td>tr</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016459</td>\n",
       "      <td>0.068960</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732240</th>\n",
       "      <td>tr_52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>26247.0</td>\n",
       "      <td>tr</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>0.080352</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732241</th>\n",
       "      <td>tr_52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>26247.0</td>\n",
       "      <td>tr</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024841</td>\n",
       "      <td>0.055587</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732242</th>\n",
       "      <td>tr_52</td>\n",
       "      <td>42632.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>26247.0</td>\n",
       "      <td>tr</td>\n",
       "      <td>1.624262</td>\n",
       "      <td>0.017602</td>\n",
       "      <td>0.033909</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1732243 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subid  firstrun.gopast  firstfix.dur     dur  total_dur lang  \\\n",
       "0        DU_04              0.0         278.0   464.0     5486.0   du   \n",
       "1        DU_04            944.0         164.0   480.0     5486.0   du   \n",
       "2        DU_04            155.0         155.0   155.0     5486.0   du   \n",
       "3        DU_04            323.0         323.0   323.0     5486.0   du   \n",
       "4        DU_04            462.0         265.0   462.0     5486.0   du   \n",
       "...        ...              ...           ...     ...        ...  ...   \n",
       "1732238  tr_52              0.0         560.0  1598.0    26247.0   tr   \n",
       "1732239  tr_52              0.0         432.0  1810.0    26247.0   tr   \n",
       "1732240  tr_52              0.0         766.0  2109.0    26247.0   tr   \n",
       "1732241  tr_52              0.0         652.0  1459.0    26247.0   tr   \n",
       "1732242  tr_52          42632.0         462.0   890.0    26247.0   tr   \n",
       "\n",
       "          FF_norm   FP_norm   TF_norm  lang_code  \n",
       "0        0.000000  0.050674  0.084579          0  \n",
       "1        0.172074  0.029894  0.087495          0  \n",
       "2        0.028254  0.028254  0.028254          0  \n",
       "3        0.058877  0.058877  0.058877          0  \n",
       "4        0.084214  0.048305  0.084214          0  \n",
       "...           ...       ...       ...        ...  \n",
       "1732238  0.000000  0.021336  0.060883         11  \n",
       "1732239  0.000000  0.016459  0.068960         11  \n",
       "1732240  0.000000  0.029184  0.080352         11  \n",
       "1732241  0.000000  0.024841  0.055587         11  \n",
       "1732242  1.624262  0.017602  0.033909         11  \n",
       "\n",
       "[1732243 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg NLIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5, multi_class='multinomial', solver='lbfgs', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['FF_norm', 'FP_norm', 'TF_norm'] # more cols for additional task of training on more columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cross_val_scores \u001b[39m=\u001b[39m get_cv_score(df, train_cols, \u001b[39m\"\u001b[39;49m\u001b[39mLogisticRegression\u001b[39;49m\u001b[39m\"\u001b[39;49m, logreg)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmean(cross_val_scores))\n",
      "File \u001b[0;32m/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/NLP/NLP_project/ANLP_project/scripts/functions.py:61\u001b[0m, in \u001b[0;36mget_cv_score\u001b[0;34m(data, columns, model_type, model, cv)\u001b[0m\n\u001b[1;32m     58\u001b[0m cv_scores \u001b[39m=\u001b[39m []\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLogisticRegression\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mfor\u001b[39;00m train_idx, test_idx \u001b[39min\u001b[39;00m tqdm(gss\u001b[39m.\u001b[39msplit(train_subset, train_label_subset, groups \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39msubid\u001b[39m\u001b[39m'\u001b[39m])): \u001b[39m# wtf what are labels\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         model\u001b[39m.\u001b[39mfit(train_subset\u001b[39m.\u001b[39miloc[train_idx], train_label_subset\u001b[39m.\u001b[39miloc[train_idx])\n\u001b[1;32m     63\u001b[0m         score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mscore(train_subset\u001b[39m.\u001b[39miloc[test_idx], train_label_subset\u001b[39m.\u001b[39miloc[test_idx])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "cross_val_scores = get_cv_score(df, train_cols, \"LogisticRegression\", logreg)\n",
    "print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, test_lang = custom_train_test_split(df, train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/NLP/NLP_project/ANLP_project/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "test_acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#print(f'Test set accuracy: {test_acc_score}; overall cross validation accuracy\" {np.mean(cross_val_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get other metrics as well, maybe store and analyze output?\n",
    "# write predictions\n",
    "# out path\n",
    "# np.savetxt(r\"../data/outputs/NLIR_predictions_logreg.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['lang'] = test_lang # add language column\n",
    "languages = list(test_lang.unique())\n",
    "dict_lang = {}\n",
    "for ll in languages:\n",
    "    df = X_test[X_test['lang'] == ll]\n",
    "    dict_lang[ll] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double for loop: for each key/df in dict -> predict, record pred as dict, put to df? and get mean s meatric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FF_norm</th>\n",
       "      <th>FP_norm</th>\n",
       "      <th>TF_norm</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050674</td>\n",
       "      <td>0.084579</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.172074</td>\n",
       "      <td>0.029894</td>\n",
       "      <td>0.087495</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058877</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084214</td>\n",
       "      <td>0.048305</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548361</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126645</td>\n",
       "      <td>0.152259</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548362</th>\n",
       "      <td>0.058281</td>\n",
       "      <td>0.058281</td>\n",
       "      <td>0.058281</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548363</th>\n",
       "      <td>0.136319</td>\n",
       "      <td>0.201515</td>\n",
       "      <td>0.308528</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548364</th>\n",
       "      <td>0.329602</td>\n",
       "      <td>0.062232</td>\n",
       "      <td>0.157392</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548365</th>\n",
       "      <td>0.037019</td>\n",
       "      <td>0.113685</td>\n",
       "      <td>0.155481</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72907 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FF_norm   FP_norm   TF_norm lang\n",
       "0        0.000000  0.050674  0.084579   du\n",
       "1        0.172074  0.029894  0.087495   du\n",
       "2        0.028254  0.028254  0.028254   du\n",
       "3        0.058877  0.058877  0.058877   du\n",
       "4        0.084214  0.048305  0.084214   du\n",
       "...           ...       ...       ...  ...\n",
       "1548361  0.000000  0.126645  0.152259   du\n",
       "1548362  0.058281  0.058281  0.058281   du\n",
       "1548363  0.136319  0.201515  0.308528   du\n",
       "1548364  0.329602  0.062232  0.157392   du\n",
       "1548365  0.037019  0.113685  0.155481   du\n",
       "\n",
       "[72907 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_lang['du']#[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['du', 'ee', 'fi', 'ge', 'gr', 'he', 'it', 'en', 'no', 'ru', 'sp', 'tr'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_proba ={}\n",
    "for key in dict_lang.keys():\n",
    "    test_proba = logreg.predict_proba(dict_lang[key][train_cols])\n",
    "    dict_proba[key] = test_proba\n",
    "    # write logreg predicted classes as col and have key lang as rows.\n",
    "    # nope lang as cols and predictions as rows bc dict structure. then can map better ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_proba ={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(dict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.classes_ # now map from lang code to lang. write external function to map and unmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04921869, 0.11924527, 0.10763136, ..., 0.08447535, 0.06897935,\n",
       "        0.03995224],\n",
       "       [0.04515644, 0.11346616, 0.09746004, ..., 0.08097361, 0.07399716,\n",
       "        0.04168536],\n",
       "       [0.04814203, 0.11560505, 0.10773757, ..., 0.08345771, 0.06689759,\n",
       "        0.03899432],\n",
       "       ...,\n",
       "       [0.06363794, 0.14859503, 0.13145295, ..., 0.09593921, 0.06338954,\n",
       "        0.03767961],\n",
       "       [0.04654687, 0.11844404, 0.0979013 , ..., 0.08257245, 0.07612656,\n",
       "        0.04244673],\n",
       "       [0.05620283, 0.13185129, 0.12173659, ..., 0.09025828, 0.0640588 ,\n",
       "        0.03797565]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36e1fa312ac715c21bb59b9e6c10d6a9544a6eb8fd53fcf02705de1881480231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
