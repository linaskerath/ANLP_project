{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_test_split(data, columns):\n",
    "    \"\"\"\n",
    "    Function for train test split.\n",
    "    Arguments:\n",
    "        data: pandas dataset (with train columns, labels ('lang_code') and groups ('subid'))\n",
    "        columns: columns to train on.\n",
    "    Returns: train and test sets with labels.\n",
    "    \"\"\"\n",
    "    train_subset = data[columns]\n",
    "    train_label_subset = data['lang_code']\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size = 0.4, random_state=42)\n",
    "    split_indexes = list(gss.split(train_subset, train_label_subset, data['subid']))[0]\n",
    "    train_idx = list(split_indexes[0])\n",
    "    test_idx = list(split_indexes[1])\n",
    "\n",
    "    X_train = train_subset.iloc[train_idx]\n",
    "    y_train = train_label_subset.iloc[train_idx]\n",
    "    X_test = train_subset.iloc[test_idx]\n",
    "    y_test = train_label_subset.iloc[test_idx]\n",
    "\n",
    "    test_lang = data['lang'].iloc[test_idx]\n",
    "    return X_train, X_test, y_train, y_test, test_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_score(data, columns, model_type, model, cv = 5):\n",
    "    \"\"\"\n",
    "    Function to get cv score. \n",
    "    Arguments:\n",
    "        data: pandas dataset (with train columns, labels ('lang_code') and groups ('subid'))\n",
    "        columns: columns to train on.\n",
    "        model_type: LogisticRegression or LSTM.\n",
    "        model: defined model.\n",
    "        cv: how many cv splits, default = 5.\n",
    "    Returns: train and test sets with labels.\n",
    "    \"\"\"\n",
    "    train_subset = data[columns]\n",
    "    train_label_subset = data['lang_code']\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits = cv, test_size = 0.4, random_state=42)\n",
    "    cv_scores = []\n",
    "\n",
    "    if model_type == 'LogisticRegression':\n",
    "        for train_idx, test_idx in tqdm(gss.split(train_subset, train_label_subset, groups = data['subid'])): # wtf what are labels\n",
    "            model.fit(train_subset.iloc[train_idx], train_label_subset.iloc[train_idx])\n",
    "            score = model.score(train_subset.iloc[test_idx], train_label_subset.iloc[test_idx])\n",
    "            cv_scores.append(score)\n",
    "        print(np.mean(cv_scores))\n",
    "        return cv_scores\n",
    "\n",
    "    elif model_type == 'LSTM':\n",
    "        print('TBD. Must be implemented if logreg framwork does not work.')\n",
    "        return \n",
    "\n",
    "    else:\n",
    "        print(\"Model type must be 'LogisticRegression' or 'LSTM'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extended_path = r\"../data/data_extended_v1_1/data_v1_1.csv\"\n",
    "df = pd.read_csv(data_extended_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg NLIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5, multi_class='multinomial', solver='lbfgs', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/NLP/NLP_project/ANLP_project/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/NLP/NLP_project/ANLP_project/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/NLP/NLP_project/ANLP_project/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/NLP/NLP_project/ANLP_project/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10766933200140638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/NLP/NLP_project/ANLP_project/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12052354462300001,\n",
       " 0.09862741399573424,\n",
       " 0.12235904605331728,\n",
       " 0.08941046432303136,\n",
       " 0.10742619101194907]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = ['FF_norm', 'FP_norm', 'TF_norm'] # more cols for additional task of training on more columns.\n",
    "cross_val_scores = get_cv_score(df, train_cols, \"LogisticRegression\", logreg)\n",
    "print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, test_lang = custom_train_test_split(df, train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/NLP/NLP_project/ANLP_project/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "test_acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#print(f'Test set accuracy: {test_acc_score}; overall cross validation accuracy\" {np.mean(cross_val_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get other metrics as well, maybe store and analyze output?\n",
    "# write predictions\n",
    "# out path\n",
    "# np.savetxt(r\"../data/outputs/NLIR_predictions_logreg.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['lang'] = test_lang # add language column\n",
    "languages = list(test_lang.unique())\n",
    "dict_lang = {}\n",
    "for ll in languages:\n",
    "    df = X_test[X_test['lang'] == ll]\n",
    "    dict_lang[ll] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double for loop: for each key/df in dict -> predict, record pred as dict, put to df? and get mean s meatric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FF_norm</th>\n",
       "      <th>FP_norm</th>\n",
       "      <th>TF_norm</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050674</td>\n",
       "      <td>0.084579</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.172074</td>\n",
       "      <td>0.029894</td>\n",
       "      <td>0.087495</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058877</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084214</td>\n",
       "      <td>0.048305</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548361</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126645</td>\n",
       "      <td>0.152259</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548362</th>\n",
       "      <td>0.058281</td>\n",
       "      <td>0.058281</td>\n",
       "      <td>0.058281</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548363</th>\n",
       "      <td>0.136319</td>\n",
       "      <td>0.201515</td>\n",
       "      <td>0.308528</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548364</th>\n",
       "      <td>0.329602</td>\n",
       "      <td>0.062232</td>\n",
       "      <td>0.157392</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548365</th>\n",
       "      <td>0.037019</td>\n",
       "      <td>0.113685</td>\n",
       "      <td>0.155481</td>\n",
       "      <td>du</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72907 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FF_norm   FP_norm   TF_norm lang\n",
       "0        0.000000  0.050674  0.084579   du\n",
       "1        0.172074  0.029894  0.087495   du\n",
       "2        0.028254  0.028254  0.028254   du\n",
       "3        0.058877  0.058877  0.058877   du\n",
       "4        0.084214  0.048305  0.084214   du\n",
       "...           ...       ...       ...  ...\n",
       "1548361  0.000000  0.126645  0.152259   du\n",
       "1548362  0.058281  0.058281  0.058281   du\n",
       "1548363  0.136319  0.201515  0.308528   du\n",
       "1548364  0.329602  0.062232  0.157392   du\n",
       "1548365  0.037019  0.113685  0.155481   du\n",
       "\n",
       "[72907 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_lang['du']#[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['du', 'ee', 'fi', 'ge', 'gr', 'he', 'it', 'en', 'no', 'ru', 'sp', 'tr'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in dict_lang.keys():\n",
    "    test_proba = logreg.predict_proba(dict_lang[key][train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.classes_ # now map from lang code to lang. write external function to map and unmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04921869, 0.11924527, 0.10763136, ..., 0.08447535, 0.06897935,\n",
       "        0.03995224],\n",
       "       [0.04515644, 0.11346616, 0.09746004, ..., 0.08097361, 0.07399716,\n",
       "        0.04168536],\n",
       "       [0.04814203, 0.11560505, 0.10773757, ..., 0.08345771, 0.06689759,\n",
       "        0.03899432],\n",
       "       ...,\n",
       "       [0.06363794, 0.14859503, 0.13145295, ..., 0.09593921, 0.06338954,\n",
       "        0.03767961],\n",
       "       [0.04654687, 0.11844404, 0.0979013 , ..., 0.08257245, 0.07612656,\n",
       "        0.04244673],\n",
       "       [0.05620283, 0.13185129, 0.12173659, ..., 0.09025828, 0.0640588 ,\n",
       "        0.03797565]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on same data as training or need different data?\n",
    "#score = logreg.score()\n",
    "# X - put spanish\n",
    "# y - put portuguese and see how high the accuracy? or see how often predicted portuguese?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36e1fa312ac715c21bb59b9e6c10d6a9544a6eb8fd53fcf02705de1881480231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
