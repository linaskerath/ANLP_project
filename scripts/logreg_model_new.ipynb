{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "redo model training with new data in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdata\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import json\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from functions import get_cv_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/df_uni_bi_tri.pickle\")\n",
    "df =df.reset_index(col_level=1).rename(columns = {'': 'id'}, level =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add language that is going to be the label/ target for model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read df with language:\n",
    "path_ind_diff = r\"../data/version 1.1/primary data/individual differences data/joint.ind.diff.l2.rda\"\n",
    "parsed_readrate = rdata.parser.parse_file(path_ind_diff)\n",
    "converted_readrate = rdata.conversion.convert(parsed_readrate)\n",
    "df_readrate = converted_readrate['joint_id'][['uniform_id', 'lang']]\n",
    "\n",
    "# need multiindex to merge properly:\n",
    "df_readrate.columns = pd.MultiIndex.from_product([['labels'], df_readrate.columns]) \n",
    "\n",
    "# join language\n",
    "df_main = df.merge(df_readrate, left_on = [('id', 'uniform_id')], right_on= [('labels', 'uniform_id')])\n",
    "df_main = df_main.drop([('labels', 'uniform_id')], axis=1)\n",
    "\n",
    "# encode language as lables ( using old lookup json):\n",
    "with open(\"../data/outputs/language_lookup.json\") as json_file:\n",
    "    language_lookup = json.load(json_file)\n",
    "\n",
    "df_main[('labels', 'lang_code')] = df_main[('labels', 'lang')].replace(language_lookup).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### only for 4 lang check: #####\n",
    "#df_main[('labels', 'lang')].unique()\n",
    "# use ee-fi and it-sp\n",
    "df_main = df_main[df_main[('labels', 'lang')].isin(['ee', 'fi', 'it', 'sp'])]\n",
    "\n",
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg NLIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model with correct solver\n",
    "logreg = LogisticRegression(C=1e5, multi_class='multinomial', solver='lbfgs', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns used in training\n",
    "columns = ['TF_uni', 'FP_uni', 'FF_uni', 'TF_bi', 'FP_bi', 'FF_bi', 'TF_tri', 'FP_tri', 'FF_tri' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation score: \n",
    "\n",
    "(only needed for report and not for further coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:01,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4914285714285714\n",
      "0.4914285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cross_val_scores = get_cv_score(df_main, columns, logreg)\n",
    "print(np.mean(cross_val_scores))\n",
    "#cross_val_scores # [0.65, 0.5666666666666667, 0.6, 0.5166666666666667, 0.5666666666666667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real train-test split to be used for further analysis: \n",
    "train_subset = df_main[columns]\n",
    "train_label_subset = df_main[('labels', 'lang_code')]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=5, test_size = 0.3, random_state=42)\n",
    "split_indexes = list(gss.split(train_subset, train_label_subset, df_main[('id','uniform_id')]))[0]\n",
    "train_idx = list(split_indexes[0])\n",
    "test_idx = list(split_indexes[1])\n",
    "\n",
    "X_train = train_subset.iloc[train_idx]\n",
    "y_train = train_label_subset.iloc[train_idx]\n",
    "X_test = train_subset.iloc[test_idx]\n",
    "y_test = train_label_subset.iloc[test_idx]\n",
    "\n",
    "test_lang = df_main[('labels', 'lang')].iloc[test_idx]\n",
    "test_lang_codes = df_main[('labels', 'lang_code')].iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.4074074074074074; overall cross validation accuracy 0.4914285714285714\n"
     ]
    }
   ],
   "source": [
    "# fit model:\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# only for score count:\n",
    "y_pred = logreg.predict(X_test)\n",
    "test_acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {test_acc_score}; overall cross validation accuracy {np.mean(cross_val_scores)}')\n",
    "# Test set accuracy: 0.6888888888888889; overall cross validation accuracy 0.5800000000000001 for all languages\n",
    "# Test set accuracy: 0.4074074074074074; overall cross validation accuracy 0.4914285714285714 for 4 languages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary with df for each language separately to be used for similarity metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2200/2390796384.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['lang'] = test_lang # add language column\n"
     ]
    }
   ],
   "source": [
    "X_test['lang'] = test_lang # add language column\n",
    "languages = list(test_lang.unique())\n",
    "dict_lang = {}\n",
    "for ll in languages:\n",
    "    df = X_test[X_test['lang'] == ll]\n",
    "    dict_lang[ll] = df\n",
    "\n",
    "\n",
    "dict_proba ={}\n",
    "len_dfs = []\n",
    "lang_identifier = []\n",
    "for key in dict_lang.keys():\n",
    "    lang_df = dict_lang[key][columns]\n",
    "    test_proba = logreg.predict_proba(lang_df) # predicting probabilities here\n",
    "    len_df = len(lang_df)\n",
    "    test_proba = test_proba.sum(axis=0)   # sum bc they are normalised by number of participants\n",
    "    dict_proba[key] = test_proba\n",
    "    len_dfs.append(len_df) # record length of language df\n",
    "    lang_identifier.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to pandas:\n",
    "df_predictions = pd.DataFrame(dict_proba).reset_index()\n",
    "# cols are lang on which predicted and rows are outputs\n",
    "\n",
    "# add col with lenghts and lang name\n",
    "df_predictions['length'] = len_dfs\n",
    "df_predictions['lang'] = lang_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ee</th>\n",
       "      <th>fi</th>\n",
       "      <th>it</th>\n",
       "      <th>sp</th>\n",
       "      <th>length</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.008800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.155617e-17</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>9</td>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.820599</td>\n",
       "      <td>1.979845</td>\n",
       "      <td>5.632468e-08</td>\n",
       "      <td>1.888169</td>\n",
       "      <td>5</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.998007</td>\n",
       "      <td>3.453242e+00</td>\n",
       "      <td>1.368055</td>\n",
       "      <td>4</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.170571</td>\n",
       "      <td>1.022147</td>\n",
       "      <td>5.467576e-01</td>\n",
       "      <td>4.743580</td>\n",
       "      <td>9</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        ee        fi            it        sp  length lang\n",
       "0      0  1.008800  1.000000  5.155617e-17  1.000196       9   ee\n",
       "1      1  2.820599  1.979845  5.632468e-08  1.888169       5   fi\n",
       "2      2  0.000030  0.998007  3.453242e+00  1.368055       4   it\n",
       "3      3  5.170571  1.022147  5.467576e-01  4.743580       9   sp"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into pair dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_values = []\n",
    "lang_pairs = []\n",
    "#lang_similarities = {}\n",
    "for key1 in df_predictions['lang'].unique(): \n",
    "    for key2 in df_predictions['lang'].unique(): \n",
    "        val1 = float(df_predictions[df_predictions['lang'] == key1][key2])\n",
    "        val2 = float(df_predictions[df_predictions['lang'] == key2][key1])\n",
    "        len1 = float(df_predictions[df_predictions['lang'] == key1]['length'])\n",
    "        len2 = float(df_predictions[df_predictions['lang'] == key2]['length'])\n",
    "        \n",
    "        #lang_similarities[f'{key1}_{key2}'] = ((val1 + val2) /(len1+len2)) #  divide by corpus length bc summed above\n",
    "        lang_values.append((val1 + val2) / (len1+len2))\n",
    "        lang_pairs.append(f'{key1}_{key2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lang_similarities = pd.DataFrame({'pair': lang_pairs, 'logreg_val': lang_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted \n",
    "df_lang_similarities['logreg_val_inverted'] = 1 - df_lang_similarities['logreg_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>logreg_val</th>\n",
       "      <th>logreg_val_inverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ee_ee</td>\n",
       "      <td>0.112089</td>\n",
       "      <td>0.887911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee_fi</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>0.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee_it</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ee_sp</td>\n",
       "      <td>0.342820</td>\n",
       "      <td>0.657180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fi_ee</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>0.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fi_fi</td>\n",
       "      <td>0.395969</td>\n",
       "      <td>0.604031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fi_it</td>\n",
       "      <td>0.110890</td>\n",
       "      <td>0.889110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fi_sp</td>\n",
       "      <td>0.207880</td>\n",
       "      <td>0.792120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it_ee</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it_fi</td>\n",
       "      <td>0.110890</td>\n",
       "      <td>0.889110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>it_it</td>\n",
       "      <td>0.863311</td>\n",
       "      <td>0.136689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it_sp</td>\n",
       "      <td>0.147293</td>\n",
       "      <td>0.852707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sp_ee</td>\n",
       "      <td>0.342820</td>\n",
       "      <td>0.657180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sp_fi</td>\n",
       "      <td>0.207880</td>\n",
       "      <td>0.792120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sp_it</td>\n",
       "      <td>0.147293</td>\n",
       "      <td>0.852707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sp_sp</td>\n",
       "      <td>0.527064</td>\n",
       "      <td>0.472936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pair  logreg_val  logreg_val_inverted\n",
       "0   ee_ee    0.112089             0.887911\n",
       "1   ee_fi    0.272900             0.727100\n",
       "2   ee_it    0.000002             0.999998\n",
       "3   ee_sp    0.342820             0.657180\n",
       "4   fi_ee    0.272900             0.727100\n",
       "5   fi_fi    0.395969             0.604031\n",
       "6   fi_it    0.110890             0.889110\n",
       "7   fi_sp    0.207880             0.792120\n",
       "8   it_ee    0.000002             0.999998\n",
       "9   it_fi    0.110890             0.889110\n",
       "10  it_it    0.863311             0.136689\n",
       "11  it_sp    0.147293             0.852707\n",
       "12  sp_ee    0.342820             0.657180\n",
       "13  sp_fi    0.207880             0.792120\n",
       "14  sp_it    0.147293             0.852707\n",
       "15  sp_sp    0.527064             0.472936"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lang_similarities # invert as 1- proba. \n",
    "df_lang_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write \n",
    "\n",
    "df_lang_similarities.to_csv(\"../data/outputs/logreg_similarity_4lang.csv\", index = False) # rename for other saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDos:**\n",
    "\n",
    "- investigate why 4 lang perform worse than all. maybe try with 2? ( very different and very similar - eg ee vs fi and ee and sp)\n",
    "- do separate runs with only bi and bi+tri-grams and fill table in report\n",
    "- plot language tree using both similarity metrics\n",
    "- do majority class baseline (cv accuracy only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36e1fa312ac715c21bb59b9e6c10d6a9544a6eb8fd53fcf02705de1881480231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
